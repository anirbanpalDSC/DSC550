{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd, numpy as np, json, re\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaning process\n",
    "def clean(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('&lt;/?.*?&gt;',' &lt;&gt', text)\n",
    "    text=re.sub('\\\\d|\\\\W+',' ',text)\n",
    "    return text\n",
    "\n",
    "# Create stop words list\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bernoulli NB classifier\n",
    "bnb = BernoulliNB(class_prior=[0.25, 0.5])\n",
    "\n",
    "# Create Multinomial NB classifier\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Create Logistic Regression classifier (for Penalty l1 and l2)\n",
    "cls1 = LogisticRegression(penalty = 'l1', solver = 'saga', multi_class = 'auto')\n",
    "cls2 = LogisticRegression(penalty = 'l2', solver = 'saga', multi_class = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the source data file for Categorized data\n",
    "file = 'data/reddit/categorized-comments.jsonl'\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(file) as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "# Convert to Data Frame\n",
    "category = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2347476 entries, 0 to 2347475\n",
      "Data columns (total 2 columns):\n",
      "cat    object\n",
      "txt    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ MB\n",
      "Size:  2347476 \n",
      " Shape:  None \n",
      " Categories:  ['sports' 'science_and_technology' 'video_games' 'news']\n"
     ]
    }
   ],
   "source": [
    "# Check size of the total data\n",
    "# Check structure\n",
    "# Check categories\n",
    "print('Size: ', len(category), '\\n',\n",
    "      'Shape: ', category.info(), '\\n',\n",
    "      'Categories: ', category.cat.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">news</th>\n",
       "      <th>1590595</th>\n",
       "      <td>news</td>\n",
       "      <td>Because sex and gender isn't the same thing?\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575344</th>\n",
       "      <td>news</td>\n",
       "      <td>you been smoking some treated ganja dude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231459</th>\n",
       "      <td>news</td>\n",
       "      <td>Funny how I've heard long winded discussions f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228315</th>\n",
       "      <td>news</td>\n",
       "      <td>Eh what does she actually do though?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144152</th>\n",
       "      <td>news</td>\n",
       "      <td>because it's not a one way street, sure it mig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat                                                txt\n",
       "cat                                                                  \n",
       "news 1590595  news  Because sex and gender isn't the same thing?\\n...\n",
       "     1575344  news           you been smoking some treated ganja dude\n",
       "     2231459  news  Funny how I've heard long winded discussions f...\n",
       "     2228315  news              Eh what does she actually do though? \n",
       "     2144152  news  because it's not a one way street, sure it mig..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the size is humongus, I will take sample of all 4 categories. \n",
    "# By trial, sample of 1000 from each category can be easily handled by my machine\n",
    "sample = category.groupby('cat').apply(lambda x :x.sample(1000))\n",
    "del category\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "sample['txt'] = sample['txt'].apply(lambda x:clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature matrix\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "txtvec = cv.fit_transform(sample['txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target and sample\n",
    "target_cat = sample['cat']\n",
    "features_cat = txtvec\n",
    "\n",
    "# Create train test split\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_cat, target_cat, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Accuracy of Maultinomial training:  0.8236666666666667\n",
      "Cat Accuracy of Maultinomial test:  0.845\n"
     ]
    }
   ],
   "source": [
    "# Create NB Multinomial model\n",
    "model_catMNB = mnb.fit(features_cat, target_cat)\n",
    "\n",
    "train_predMNB = model_catMNB.predict(features_train)\n",
    "test_predMNB = model_catMNB.predict(features_test)\n",
    "\n",
    "accuracy_train_catMNB = accuracy_score(target_train, train_predMNB)\n",
    "accuracy_test_catMNB = accuracy_score(target_test, test_predMNB)\n",
    "\n",
    "print('Cat Accuracy of Maultinomial training: ', accuracy_train_catMNB)\n",
    "print('Cat Accuracy of Maultinomial test: ', accuracy_test_catMNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anirban\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Accuracy with penalty l1:  0.516 0.6706666666666666\n",
      "Cat Accuracy with penalty l2:  0.549 0.8206666666666667\n"
     ]
    }
   ],
   "source": [
    "# Create Logistic Regression model(s)\n",
    "model_cat_LR1 = cls1.fit(features_train, target_train)\n",
    "model_cat_LR2 = cls2.fit(features_train, target_train)\n",
    "\n",
    "# Apply model to predict\n",
    "test_pred1 = model_cat_LR1.predict(features_test)\n",
    "train_pred1 = model_cat_LR1.predict(features_train)\n",
    "\n",
    "test_pred2 = model_cat_LR2.predict(features_test)\n",
    "train_pred2 = model_cat_LR2.predict(features_train)\n",
    "\n",
    "# Measure accuracy\n",
    "accuracy_test_catLR1 = accuracy_score(target_test, test_pred1)\n",
    "accuracy_train_catLR1 = accuracy_score(target_train, train_pred1)\n",
    "\n",
    "accuracy_test_catLR2 = accuracy_score(target_test, test_pred2)\n",
    "accuracy_train_catLR2 = accuracy_score(target_train, train_pred2)\n",
    "\n",
    "print('Cat Accuracy with penalty l1: ', accuracy_test_catLR1, accuracy_train_catLR1)\n",
    "print('Cat Accuracy with penalty l2: ', accuracy_test_catLR2, accuracy_train_catLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory by unloading unnecessery data set\n",
    "\n",
    "del sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controversy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the source data file for Categorized data\n",
    "file = 'data/reddit/controversial-comments.jsonl'\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(file) as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "# Convert to Data Frame\n",
    "controversy = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 950000 entries, 0 to 949999\n",
      "Data columns (total 2 columns):\n",
      "con    950000 non-null int64\n",
      "txt    950000 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 10.9+ MB\n",
      "Size:  950000 \n",
      " Shape:  None \n",
      " Categories:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Check size of the total data\n",
    "# Check structure\n",
    "# Check categories\n",
    "print('Size: ', len(controversy), '\\n',\n",
    "      'Shape: ', controversy.info(), '\\n',\n",
    "      'Categories: ', controversy.con.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>867329</th>\n",
       "      <td>0</td>\n",
       "      <td>I know. Any way you slice it, he was lying.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342181</th>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928492</th>\n",
       "      <td>0</td>\n",
       "      <td>My point still stands, All these polls are utt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586530</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, there's a political system that's yet to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591565</th>\n",
       "      <td>0</td>\n",
       "      <td>Look again where the linked article is from...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          con                                                txt\n",
       "0 867329    0        I know. Any way you slice it, he was lying.\n",
       "  342181    0                                               good\n",
       "  928492    0  My point still stands, All these polls are utt...\n",
       "  586530    0  Hey, there's a political system that's yet to ...\n",
       "  591565    0     Look again where the linked article is from..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the size is humongus, I will take sample of the 2 categories. \n",
    "# By trial, sample of 50000 from each category can be easily handled by my machine\n",
    "size = 50000    # sample size\n",
    "replace = True  # with replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "cont = controversy.groupby('con', as_index=False).apply(fn)\n",
    "\n",
    "del controversy\n",
    "\n",
    "cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "cont['txt'] = cont['txt'].apply(lambda x:clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature matrix\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "txtvec = cv.fit_transform(cont['txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target and sample\n",
    "target_con = cont['con']\n",
    "features_con = txtvec\n",
    "\n",
    "# Create train test split\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_con, target_con, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con Accuracy of Bernoulli training:  0.6247733333333333\n",
      "Con Accuracy of Bernoulli test:  0.62388\n"
     ]
    }
   ],
   "source": [
    "# Train model for Bernoulli\n",
    "modelBNB = bnb.fit(features_con, target_con)\n",
    "\n",
    "train_predBNB = modelBNB.predict(features_train)\n",
    "test_predBNB = modelBNB.predict(features_test)\n",
    "\n",
    "accuracy_train_conBNB = accuracy_score(target_train, train_predBNB)\n",
    "accuracy_test_conBNB = accuracy_score(target_test, test_predBNB)\n",
    "\n",
    "print('Con Accuracy of Bernoulli training: ', accuracy_train_conBNB)\n",
    "print('Con Accuracy of Bernoulli test: ', accuracy_test_conBNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anirban\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con Accuracy with penalty l1:  0.61688 0.65192\n",
      "Con Accuracy with penalty l2:  0.62112 0.6608933333333333\n"
     ]
    }
   ],
   "source": [
    "# Train model for Logistic Regression\n",
    "model_con_LR1 = cls1.fit(features_train, target_train)\n",
    "model_con_LR2 = cls2.fit(features_train, target_train)\n",
    "\n",
    "# Apply model to predict\n",
    "test_pred1 = model_con_LR1.predict(features_test)\n",
    "train_pred1 = model_con_LR1.predict(features_train)\n",
    "\n",
    "test_pred2 = model_con_LR2.predict(features_test)\n",
    "train_pred2 = model_con_LR2.predict(features_train)\n",
    "\n",
    "# Measure accuracy\n",
    "accuracy_test_conLR1 = accuracy_score(target_test, test_pred1)\n",
    "accuracy_train_conLR1 = accuracy_score(target_train, train_pred1)\n",
    "\n",
    "accuracy_test_conLR2 = accuracy_score(target_test, test_pred2)\n",
    "accuracy_train_conLR2 = accuracy_score(target_train, train_pred2)\n",
    "\n",
    "print('Con Accuracy with penalty l1: ', accuracy_test_conLR1, accuracy_train_conLR1)\n",
    "print('Con Accuracy with penalty l2: ', accuracy_test_conLR2, accuracy_train_conLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Accuracy_Train</th>\n",
       "      <th>Accuracy_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression(L1)</td>\n",
       "      <td>Controversy</td>\n",
       "      <td>0.651920</td>\n",
       "      <td>0.61688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression(L2)</td>\n",
       "      <td>Controversy</td>\n",
       "      <td>0.660893</td>\n",
       "      <td>0.62112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Controversy</td>\n",
       "      <td>0.624773</td>\n",
       "      <td>0.62388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression(L1)</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.670667</td>\n",
       "      <td>0.51600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression(L2)</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.820667</td>\n",
       "      <td>0.54900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.823667</td>\n",
       "      <td>0.84500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model     Data Set  Accuracy_Train  Accuracy_Test\n",
       "0  Logistic Regression(L1)  Controversy        0.651920        0.61688\n",
       "1  Logistic Regression(L2)  Controversy        0.660893        0.62112\n",
       "2              Naive Bayes  Controversy        0.624773        0.62388\n",
       "3  Logistic Regression(L1)     Category        0.670667        0.51600\n",
       "4  Logistic Regression(L2)     Category        0.820667        0.54900\n",
       "5              Naive Bayes     Category        0.823667        0.84500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create final output data frame for accuracy\n",
    "accuracy = {'Model':['Logistic Regression(L1)',\n",
    "                     'Logistic Regression(L2)',\n",
    "                     'Naive Bayes',\n",
    "                     'Logistic Regression(L1)',\n",
    "                     'Logistic Regression(L2)',\n",
    "                     'Naive Bayes',\n",
    "                    ], \n",
    "            'Data Set':['Controversy',\n",
    "                        'Controversy',\n",
    "                        'Controversy',\n",
    "                        'Category',\n",
    "                        'Category',\n",
    "                        'Category',\n",
    "                       ],\n",
    "            'Accuracy_Train':[accuracy_train_conLR1,\n",
    "                              accuracy_train_conLR2,\n",
    "                              accuracy_train_conBNB,\n",
    "                              accuracy_train_catLR1,\n",
    "                              accuracy_train_catLR2,\n",
    "                              accuracy_train_catMNB\n",
    "                             ],\n",
    "            'Accuracy_Test':[accuracy_test_conLR1,\n",
    "                              accuracy_test_conLR2,\n",
    "                              accuracy_test_conBNB,\n",
    "                              accuracy_test_catLR1,\n",
    "                              accuracy_test_catLR2,\n",
    "                              accuracy_test_catMNB\n",
    "                            ]\n",
    "           } \n",
    "  \n",
    "# Create DataFrame \n",
    "df_accuracy = pd.DataFrame(accuracy)\n",
    "  \n",
    "# Print the output\n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of code**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
