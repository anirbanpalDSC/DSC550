{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature Reduction**\n",
    "\n",
    "In the first part of this exercise, you will use the feature_selection.csv dataset. You will fit a logistic regression classifier to this dataset holding out 33% of the data for training. You will experiment with different feature selection and dimensionality reduction techniques.\n",
    "\n",
    "Fit the data without using any feature reduction\n",
    "Compute a correlation matrix and drop features that are over 95% correlated\n",
    "Reduce the number of features using Truncated Singular Value Decomposition (TSVD) at different values of the number of components (2, 5, 10, and 20)\n",
    "Report the results in a table with the following form.\n",
    "\n",
    "<img src=\"files/Images/ex8-1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "# Ignore all future data conversion warnings\n",
    "warnings.simplefilter(action='ignore', category=(DataConversionWarning, FutureWarning))\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 818 entries, 0 to 817\n",
      "Columns: 453 entries, ID to J.c9.5\n",
      "dtypes: float64(450), int64(2), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>A.c1.1</th>\n",
       "      <th>A.c1.2</th>\n",
       "      <th>A.c1.3</th>\n",
       "      <th>A.c1.4</th>\n",
       "      <th>A.c1.5</th>\n",
       "      <th>A.c2.1</th>\n",
       "      <th>A.c2.2</th>\n",
       "      <th>...</th>\n",
       "      <th>J.c8.1</th>\n",
       "      <th>J.c8.2</th>\n",
       "      <th>J.c8.3</th>\n",
       "      <th>J.c8.4</th>\n",
       "      <th>J.c8.5</th>\n",
       "      <th>J.c9.1</th>\n",
       "      <th>J.c9.2</th>\n",
       "      <th>J.c9.3</th>\n",
       "      <th>J.c9.4</th>\n",
       "      <th>J.c9.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5560</td>\n",
       "      <td>3</td>\n",
       "      <td>typ</td>\n",
       "      <td>2.238984</td>\n",
       "      <td>3.238984</td>\n",
       "      <td>4.238984</td>\n",
       "      <td>5.238984</td>\n",
       "      <td>6.238984</td>\n",
       "      <td>2.539386</td>\n",
       "      <td>3.539386</td>\n",
       "      <td>...</td>\n",
       "      <td>2.330630</td>\n",
       "      <td>3.330630</td>\n",
       "      <td>4.330630</td>\n",
       "      <td>5.330630</td>\n",
       "      <td>6.330630</td>\n",
       "      <td>0.105146</td>\n",
       "      <td>1.105146</td>\n",
       "      <td>2.105146</td>\n",
       "      <td>3.105146</td>\n",
       "      <td>4.105146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4694</td>\n",
       "      <td>3</td>\n",
       "      <td>typ</td>\n",
       "      <td>1.490947</td>\n",
       "      <td>2.490947</td>\n",
       "      <td>3.490947</td>\n",
       "      <td>4.490947</td>\n",
       "      <td>5.490947</td>\n",
       "      <td>0.692924</td>\n",
       "      <td>1.692924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>1.033946</td>\n",
       "      <td>2.033946</td>\n",
       "      <td>3.033946</td>\n",
       "      <td>4.033946</td>\n",
       "      <td>-0.921489</td>\n",
       "      <td>0.078511</td>\n",
       "      <td>1.078511</td>\n",
       "      <td>2.078511</td>\n",
       "      <td>3.078511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6449</td>\n",
       "      <td>3</td>\n",
       "      <td>typ</td>\n",
       "      <td>1.828413</td>\n",
       "      <td>2.828413</td>\n",
       "      <td>3.828413</td>\n",
       "      <td>4.828413</td>\n",
       "      <td>5.828413</td>\n",
       "      <td>2.995978</td>\n",
       "      <td>3.995978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309544</td>\n",
       "      <td>0.690456</td>\n",
       "      <td>1.690456</td>\n",
       "      <td>2.690456</td>\n",
       "      <td>3.690456</td>\n",
       "      <td>1.838188</td>\n",
       "      <td>2.838188</td>\n",
       "      <td>3.838188</td>\n",
       "      <td>4.838188</td>\n",
       "      <td>5.838188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3008</td>\n",
       "      <td>3</td>\n",
       "      <td>asd</td>\n",
       "      <td>1.930039</td>\n",
       "      <td>2.930039</td>\n",
       "      <td>3.930039</td>\n",
       "      <td>4.930039</td>\n",
       "      <td>5.930039</td>\n",
       "      <td>2.698195</td>\n",
       "      <td>3.698195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727438</td>\n",
       "      <td>1.727438</td>\n",
       "      <td>2.727438</td>\n",
       "      <td>3.727438</td>\n",
       "      <td>4.727438</td>\n",
       "      <td>2.793029</td>\n",
       "      <td>5.793029</td>\n",
       "      <td>10.793029</td>\n",
       "      <td>17.793029</td>\n",
       "      <td>26.793029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3863</td>\n",
       "      <td>3</td>\n",
       "      <td>typ</td>\n",
       "      <td>2.272464</td>\n",
       "      <td>3.272464</td>\n",
       "      <td>4.272464</td>\n",
       "      <td>5.272464</td>\n",
       "      <td>6.272464</td>\n",
       "      <td>1.539144</td>\n",
       "      <td>2.539144</td>\n",
       "      <td>...</td>\n",
       "      <td>2.168858</td>\n",
       "      <td>3.168858</td>\n",
       "      <td>4.168858</td>\n",
       "      <td>5.168858</td>\n",
       "      <td>6.168858</td>\n",
       "      <td>-0.938000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>1.062000</td>\n",
       "      <td>2.062000</td>\n",
       "      <td>3.062000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 453 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  age class    A.c1.1    A.c1.2    A.c1.3    A.c1.4    A.c1.5  \\\n",
       "0  5560    3   typ  2.238984  3.238984  4.238984  5.238984  6.238984   \n",
       "1  4694    3   typ  1.490947  2.490947  3.490947  4.490947  5.490947   \n",
       "2  6449    3   typ  1.828413  2.828413  3.828413  4.828413  5.828413   \n",
       "3  3008    3   asd  1.930039  2.930039  3.930039  4.930039  5.930039   \n",
       "4  3863    3   typ  2.272464  3.272464  4.272464  5.272464  6.272464   \n",
       "\n",
       "     A.c2.1    A.c2.2    ...        J.c8.1    J.c8.2    J.c8.3    J.c8.4  \\\n",
       "0  2.539386  3.539386    ...      2.330630  3.330630  4.330630  5.330630   \n",
       "1  0.692924  1.692924    ...      0.033946  1.033946  2.033946  3.033946   \n",
       "2  2.995978  3.995978    ...     -0.309544  0.690456  1.690456  2.690456   \n",
       "3  2.698195  3.698195    ...      0.727438  1.727438  2.727438  3.727438   \n",
       "4  1.539144  2.539144    ...      2.168858  3.168858  4.168858  5.168858   \n",
       "\n",
       "     J.c8.5    J.c9.1    J.c9.2     J.c9.3     J.c9.4     J.c9.5  \n",
       "0  6.330630  0.105146  1.105146   2.105146   3.105146   4.105146  \n",
       "1  4.033946 -0.921489  0.078511   1.078511   2.078511   3.078511  \n",
       "2  3.690456  1.838188  2.838188   3.838188   4.838188   5.838188  \n",
       "3  4.727438  2.793029  5.793029  10.793029  17.793029  26.793029  \n",
       "4  6.168858 -0.938000  0.062000   1.062000   2.062000   3.062000  \n",
       "\n",
       "[5 rows x 453 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data in and examine \n",
    "\n",
    "feature_selection = pd.read_csv('data/feature_selection.txt', sep = ',', header=0)\n",
    "feature_selection.info()\n",
    "feature_selection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one categorical variable, `class` which needs to be converted to continuous variable for model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "asd    180\n",
       "typ    638\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking distinct categorical values to create mapping and validate\n",
    "\n",
    "feature_selection.groupby(['class']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    638\n",
       "1    180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mapping for categorical variable and replace them in the data\n",
    "\n",
    "map_class = {'typ': 0, 'asd': 1}\n",
    "feature_selection['class'] = feature_selection['class'].map(map_class)\n",
    "\n",
    "# Checking distinct continuous values to create mapping and validate\n",
    "\n",
    "feature_selection.groupby(['class']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check in the data contain any null value\n",
    "# If they do we need to treat them separately\n",
    "\n",
    "feature_selection.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no `null` value in the data frame. Therefore no need to further seggregation. Continuing to process. Going forth, the categorical dependent variable for the `logistic regression` *(Y)* is the `class` variable, and the independent variables *(Y)* are the rest of the fields in `feature_selection` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y\n",
    "\n",
    "category = 'class'\n",
    "X = feature_selection.drop([category], axis=1)\n",
    "Y = feature_selection.loc[:, category]\n",
    "\n",
    "\n",
    "def split_test_train(X, Y, size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test train split by holding specified amount of test data\n",
    "    Args: X (independent variable(s)), Y (Dependent variable(s)), size (to hold)\n",
    "    Returns: train and test datasets\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=size)\n",
    "\n",
    "    # Assuming data is normally distributed within each feature, \n",
    "    # scale them such that the distribution is now centred around 0, \n",
    "    # with a standard deviation of 1\n",
    "\n",
    "    X_sc = StandardScaler()\n",
    "    X_train = X_sc.fit_transform(X_train)\n",
    "    X_test = X_sc.fit_transform(X_test)\n",
    "    features = len(X_train)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_test_train(X, Y, 0.33)\n",
    "\n",
    "feature_none = len(feature_selection.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting logistic regression model on train and test data\n",
    "\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[209   0]\n",
      " [  0  61]]\n",
      "Model Accuracy Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Get prediction\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate accuracy by creating confusion matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "\n",
    "acc_none = lr.score(X_test, Y_test)\n",
    "\n",
    "print('Confusion Matrix: ')\n",
    "print(conf_matrix)\n",
    "print('Model Accuracy Score: ', acc_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       209\n",
      "           1       1.00      1.00      1.00        61\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Area under ROC:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report and calculate area under ROC\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print('Area under ROC:')\n",
    "print(roc_auc_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features (95%)\n",
    "# Generate correlation matrix\n",
    "\n",
    "corr_matrix = feature_selection.corr().abs()\n",
    "\n",
    "# Upper traingle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "feature_todrop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# Number of features to drop\n",
    "\n",
    "len(feature_todrop)\n",
    "\n",
    "# Drop features\n",
    "\n",
    "feature_selection = feature_selection.drop(feature_todrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Split the data (after feature reduction) to test train split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_test_train(X, Y, 0.33)\n",
    "\n",
    "# Fitting logistic regression model on train and test data\n",
    "\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "# Get prediction\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "\n",
    "acc_corrdrop = lr.score(X_test, Y_test)\n",
    "\n",
    "# Calculate number of features\n",
    "feature_corrdrop = len(feature_selection.columns)\n",
    "\n",
    "print('Model Accuracy Score: ', acc_corrdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsvd(df, component):\n",
    "    \"\"\"\n",
    "    Generate tsvd variance for number of components\n",
    "    Args: dataframe, number of components\n",
    "    Returns: Number of original features, reduced \n",
    "             features, variance ratio and total variance\n",
    "    \"\"\"\n",
    "    \n",
    "    features = StandardScaler().fit_transform(feature_selection)\n",
    "\n",
    "    # Make sparse matrix\n",
    "    features_sparse = csr_matrix(features)\n",
    "\n",
    "    # Create a TSVD\n",
    "    tsvd = TruncatedSVD(n_components=component)\n",
    "    features_sparse_tsvd = tsvd.fit(features_sparse).transform(features_sparse)\n",
    "    \n",
    "    feature_orig = features_sparse.shape[1]\n",
    "    feature_reduced = features_sparse_tsvd.shape[1]\n",
    "    \n",
    "    # Creating log model\n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    # Fit model\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # Target prediction\n",
    "    predict = lr.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(Y_test, predict)\n",
    "        \n",
    "    return feature_reduced, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature Reduction  # of input features  Accuracy\n",
      "0                      None                  453       1.0\n",
      "1  Drop Correlated Features                  115       1.0\n",
      "2                TSVD (N=2)                    2       1.0\n",
      "3                TSVD (N=5)                    5       1.0\n",
      "4               TSVD (N=10)                   10       1.0\n",
      "5               TSVD (N=20)                   20       1.0\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame({'Feature Reduction':['None', \n",
    "                                            'Drop Correlated Features',\n",
    "                                            'TSVD (N=2)',\n",
    "                                            'TSVD (N=5)',\n",
    "                                            'TSVD (N=10)',\n",
    "                                            'TSVD (N=20)'\n",
    "                                           ],\n",
    "                       '# of input features':[feature_none, \n",
    "                                              feature_corrdrop,\n",
    "                                              get_tsvd(feature_selection, 2)[0],\n",
    "                                              get_tsvd(feature_selection, 5)[0],\n",
    "                                              get_tsvd(feature_selection, 10)[0],\n",
    "                                              get_tsvd(feature_selection, 20)[0]\n",
    "                                             ],\n",
    "                       'Accuracy':[acc_none, \n",
    "                                   acc_corrdrop, \n",
    "                                   get_tsvd(feature_selection, 2)[1],\n",
    "                                   get_tsvd(feature_selection, 5)[1],\n",
    "                                   get_tsvd(feature_selection, 10)[1],\n",
    "                                   get_tsvd(feature_selection, 20)[1]\n",
    "                                  ]\n",
    "                      })\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Dimensionality Reduction in Text Classification**\n",
    "\n",
    "In an early lesson, you learned how to perform text classification. In this exercise, you will revisit the categorized-comments.jsonl dataset using dimensionality reduction techniques. For each dimensionality reduction technique, fit a logistic regression model to this dataset holding 33% of the data out for testing. Perform the following dimensionality reduction techniques.\n",
    "\n",
    "Use the word count vector as input with no dimensionality reduction applied\n",
    "Use the TF IDF vector as input with no dimensionality reduction applied\n",
    "Use the word count vector as input with principal components applied for the listed values of N\n",
    "Use the TF IDF vector as input with truncated singular value decomposition applied for the listed values of N\n",
    "\n",
    "<img src=\"files/Images/ex8-2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the source data file for Categorized data\n",
    "file = 'data/reddit/categorized-comments.jsonl'\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(file) as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "# Convert to Data Frame\n",
    "category = pd.DataFrame(data)\n",
    "\n",
    "category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2347476 entries, 0 to 2347475\n",
      "Data columns (total 2 columns):\n",
      "cat    object\n",
      "txt    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ MB\n",
      "Size:  2347476 \n",
      " Shape:  None \n",
      " Categories:  ['sports' 'science_and_technology' 'video_games' 'news']\n"
     ]
    }
   ],
   "source": [
    "# Check size of the total data\n",
    "# Check structure\n",
    "# Check categories\n",
    "print('Size: ', len(category), '\\n',\n",
    "      'Shape: ', category.info(), '\\n',\n",
    "      'Categories: ', category.cat.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">news</th>\n",
       "      <th>1418084</th>\n",
       "      <td>news</td>\n",
       "      <td>I would beg to differ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228151</th>\n",
       "      <td>news</td>\n",
       "      <td>US spends so much, because it's the only milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122333</th>\n",
       "      <td>news</td>\n",
       "      <td>But... are they just finding new customers all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561279</th>\n",
       "      <td>news</td>\n",
       "      <td>They renamed the emergency spillway the \"auxil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199842</th>\n",
       "      <td>news</td>\n",
       "      <td>any this millennium?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat                                                txt\n",
       "cat                                                                  \n",
       "news 1418084  news                             I would beg to differ.\n",
       "     2228151  news  US spends so much, because it's the only milit...\n",
       "     2122333  news  But... are they just finding new customers all...\n",
       "     1561279  news  They renamed the emergency spillway the \"auxil...\n",
       "     2199842  news                               any this millennium?"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the size is humongus, I will take sample of all 4 categories. \n",
    "# By trial, sample of 1000 from each category can be easily handled by my machine\n",
    "sample = category.groupby('cat').apply(lambda x :x.sample(1000))\n",
    "del category\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
