{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an earlier lesson, you created text classification models using logistic regression and Naive Bayes. In this exercise, you will expand on those models and learn how to properly evaluate the performance of those models and select the best model.\n",
    "\n",
    "### 1. Evaluating Binary Classifiers\n",
    "\n",
    "#### a. Model Metrics\n",
    "\n",
    "Using the same model parameters you used in the text classification exercise, the model’s accuracy, ROC AUC, precision, recall, and F1-score.\n",
    "\n",
    "<img src=\"files/Images/ex9-1.jpg\">\n",
    "\n",
    "#### b. Cross Validation\n",
    "\n",
    "Using the logistic regression model with the L2 penalty, calculate the cross-validation score of the model’s ROC AUC using three-fold cross validation.\n",
    "\n",
    "### 2. Evaluating Multi-class Classifiers\n",
    "\n",
    "Using the same data you used for the multi-class text classifier in the text classification lesson, calculate the following model metrics.\n",
    "\n",
    "#### a. Model Metrics\n",
    "\n",
    "<img src=\"files/Images/ex9-2.jpg\">\n",
    "\n",
    "#### b. Cross Validation\n",
    "\n",
    "Using the logistic regression model with the L2 penalty, calculate the cross-validation score of the model’s F1 score using three-fold cross validation.\n",
    "\n",
    "### 3. Hyperparameter Selection\n",
    "\n",
    "Use the GridSearchCV function to select the best binary classification model. For this problem, only consider the logistic regression model. For the search parameters try both L1 and L2 with C values of np.logspace(0, 4, 10). Report the cross-validation score and parameters of the best model.\n",
    "\n",
    "<img src=\"files/Images/ex9-4.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centralized import of all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, json, re, pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove punctuations and special characters, makes lower case\n",
    "    Args: text \n",
    "    Output: text\n",
    "    \"\"\"\n",
    "    \n",
    "    text=text.lower()\n",
    "    text=re.sub('&lt;/?.*?&gt;',' &lt;&gt', text)\n",
    "    text=re.sub('\\\\d|\\\\W+|_',' ',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Create stop words list\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bernoulli NB classifier\n",
    "bnb = BernoulliNB(class_prior=[0.25, 0.5])\n",
    "\n",
    "# Create Multinomial NB classifier\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Create Logistic Regression classifier (for Penalty l1 and l2)\n",
    "lr1 = LogisticRegression(penalty = 'l1', solver = 'saga', max_iter = 500, multi_class = 'auto')\n",
    "lr2 = LogisticRegression(penalty = 'l2', solver = 'saga', max_iter = 500, multi_class = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    \"\"\"\n",
    "    Take a json file location and\n",
    "    read the file into a pandas data frame\n",
    "    Args: full path to file\n",
    "    Returns: pandas dataframe with data from file\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "        \n",
    "    # convert to data frame\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evaluating Binary Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 950000 entries, 0 to 949999\n",
      "Data columns (total 2 columns):\n",
      "con    950000 non-null int64\n",
      "txt    950000 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 10.9+ MB\n",
      "Size:  950000 \n",
      " Shape:  None \n",
      " Categories:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "# read category data\n",
    "\n",
    "#cat_df = read_data('data/reddit/categorized-comments.jsonl')\n",
    "con_df = read_data('data/reddit/controversial-comments.jsonl')\n",
    "\n",
    "# check size, structure and categories\n",
    "\n",
    "print('Size: ', len(con_df), '\\n',\n",
    "      'Shape: ', con_df.info(), '\\n',\n",
    "      'Categories: ', con_df.con.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>statistically no they just use up a ton of wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>to be fair corey was also uniquely experienced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>if trump s comment about     pound hackers did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>gt clinton on the other hand was overprepared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>those type of people have always been out ther...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  statistically no they just use up a ton of wel...\n",
       "1    0  to be fair corey was also uniquely experienced...\n",
       "2    0  if trump s comment about     pound hackers did...\n",
       "3    0   gt clinton on the other hand was overprepared...\n",
       "4    0  those type of people have always been out ther..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the size is humongus, I will take sample of the 2 categories. \n",
    "# by trial, sample of 50000 from each category can be easily handled by my machine\n",
    "\n",
    "size = 50000    # sample size\n",
    "replace = True  # with replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "controversy = con_df.groupby('con', as_index=False).apply(fn)\n",
    "\n",
    "# free up memory\n",
    "\n",
    "del con_df\n",
    "\n",
    "controversy['txt'] = controversy['txt'].apply(lambda x:clean_text(x))\n",
    "controversy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "controversy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the feature matrix\n",
    "\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "# create target and sample\n",
    "\n",
    "X = cv.fit_transform(controversy['txt'])\n",
    "Y = controversy['con']\n",
    "\n",
    "def evaluate_model(X, Y, test_size, classifier):\n",
    "    \"\"\"\n",
    "    Evaluate model and return model scores\n",
    "    Args: feature, target, test set sample size (%), \n",
    "          classifier (BNB, LR1, LR2, MNB)\n",
    "    Output: model scores (accuracy, conf_matrix, auc, \n",
    "            precision, recall, fscore, support)\n",
    "    \"\"\"\n",
    "    \n",
    "    # create train test split\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=1)\n",
    "\n",
    "    # fit models  \n",
    "    \n",
    "    # Bernoulli's Naive Bayes\n",
    "    \n",
    "    if classifier == 'BNB':\n",
    "        BNB = bnb.fit(X_train, Y_train)\n",
    "        \n",
    "        Y_pred = BNB.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(Y_test, Y_pred)        \n",
    "        \n",
    "        conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "                \n",
    "        auc = roc_auc_score(Y_test, Y_pred)\n",
    "        \n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(Y_test, Y_pred, average='weighted')\n",
    "        \n",
    "        return accuracy, auc, precision, recall, fscore\n",
    "        \n",
    "    # Logistic Regression with penalty L1\n",
    "        \n",
    "    elif classifier == 'LR1':\n",
    "        LR1 = lr1.fit(X_train, Y_train)\n",
    "        \n",
    "        Y_pred = LR1.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(Y_test, Y_pred)        \n",
    "        \n",
    "        conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "                \n",
    "        auc = roc_auc_score(Y_test, Y_pred)\n",
    "        \n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(Y_test, Y_pred, average='weighted')\n",
    "        \n",
    "        return accuracy, auc, precision, recall, fscore\n",
    "        \n",
    "    # Logistic Regression with penalty L2\n",
    "        \n",
    "    elif classifier == 'LR2':\n",
    "        LR2 = lr2.fit(X_train, Y_train)\n",
    "        \n",
    "        Y_pred = LR2.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(Y_test, Y_pred)        \n",
    "        \n",
    "        conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "                \n",
    "        auc = roc_auc_score(Y_test, Y_pred)\n",
    "        \n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(Y_test, Y_pred, average='weighted')\n",
    "        \n",
    "        return accuracy, auc, precision, recall, fscore\n",
    "        \n",
    "    # Multinomial Naive Bayes\n",
    "        \n",
    "    elif classifier == 'MNB':\n",
    "        MNB = mnb.fit(X_train, Y_train)\n",
    "        \n",
    "        Y_pred = MNB.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(Y_test, Y_pred)        \n",
    "        \n",
    "        conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "                \n",
    "        auc = roc_auc_score(Y_test, Y_pred)\n",
    "        \n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(Y_test, Y_pred, average='weighted')\n",
    "        \n",
    "        return accuracy, auc, precision, recall, fscore\n",
    "    else:\n",
    "        print('Wrong calssifier')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional explanation\n",
    "I am getting non-convergence warning in the Logistic Regression model. I tried to increase the max iteration upto 500. Increasing it more might remove the warning but my CPU cannot handle more than 500. Hence, I left the iteration at 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (L1)\n",
    "\n",
    "accuracy, auc, precision, recall, fscore = evaluate_model(X, Y, 0.25, 'LR1')\n",
    "print('Logistic Regression (L1)')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('AUC: ', auc)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1-Score: ', fscore)\n",
    "\n",
    "# Logistic Regression (L2)\n",
    "\n",
    "accuracy, auc, precision, recall, fscore = evaluate_model(X, Y, 0.25, 'LR2')\n",
    "print('Logistic Regression (L2)')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('AUC: ', auc)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1-Score: ', fscore)\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "accuracy, auc, precision, recall, fscore = evaluate_model(X, Y, 0.25, 'BNB')\n",
    "print('Naive Bayes')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('AUC: ', auc)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1-Score: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=3, random_state=seed)\n",
    "#model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(lr2, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\") % (results.mean(), results.std())\n",
    "\n",
    "roc=roc_auc_score(Y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "confusion_matrix(logit1.predict(inputData),outputData)\n",
    "\n",
    "# https://www.ritchieng.com/machine-learning-cross-validation/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
